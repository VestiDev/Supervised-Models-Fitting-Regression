{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segment 3\n",
    "\n",
    "## Classification: Binary and Multiclass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define column names\n",
    "names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n",
    "\n",
    "# loading training data\n",
    "iris = pd.read_csv('iris.data', header=None, names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create design matrix X and target vector y\n",
    "X_cls = np.array(iris.iloc[:, 0:4]) # end index is exclusive\n",
    "y_cls = np.array(iris['species']) # column name is another way of indexing df\n",
    "\n",
    "# split into train and test\n",
    "X_train_cls, X_test_cls, y_train_cls, y_test_cls = train_test_split(X_cls, y_cls, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(multi_class='auto', solver='lbfgs', random_state=0).fit(X_train_cls, y_train_cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=clf.predict(X_test_cls)\n",
    "accuracy_score(y_test_cls, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-versicolor', 'Iris-setosa', 'Iris-virginica',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-setosa',\n",
       "       'Iris-versicolor', 'Iris-virginica', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-virginica', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-versicolor', 'Iris-virginica',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-virginica',\n",
       "       'Iris-setosa', 'Iris-virginica', 'Iris-setosa', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-versicolor', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-virginica', 'Iris-versicolor', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-virginica', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-setosa', 'Iris-setosa', 'Iris-versicolor',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-versicolor',\n",
       "       'Iris-virginica'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the scaler, which standarizes all the features to have mean=0 and unit variance\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train_cls)\n",
    "\n",
    "# Apply the scaler to the X training data\n",
    "X_train_cls_std = sc.transform(X_train_cls)\n",
    "\n",
    "# Apply the SAME scaler to the X test data\n",
    "X_test_cls_std = sc.transform(X_test_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.7 2.9 4.2 1.3]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.1 3.5 1.4 0.2]\n",
      " [7.7 2.8 6.7 2. ]]\n",
      "\n",
      "\n",
      "[[-0.13835603 -0.25606255  0.22188787  0.11008189]\n",
      " [ 2.14752625 -0.01449411  1.61230796  1.18405156]\n",
      " [-0.25866563 -0.01449411  0.39569038  0.37857431]\n",
      " [-0.8602136   1.19334812 -1.4002689  -1.36662641]\n",
      " [ 2.26783585 -0.497631    1.67024213  1.04980535]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_cls[:5, :5])\n",
    "print(\"\\n\")\n",
    "print(X_train_cls_std[:5, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
       "           fit_intercept=True, max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "           penalty=None, random_state=0, shuffle=True, tol=0.001,\n",
       "           validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = Perceptron(tol=1e-3, random_state=0)\n",
    "clf.fit(X_train_cls_std, y_train_cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n"
     ]
    }
   ],
   "source": [
    "# predict the response\n",
    "y_pred = clf.predict(X_test_cls_std)\n",
    "\n",
    "# evaluate accuracy\n",
    "print(accuracy_score(y_test_cls, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
